# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/Muskantomar001/0aa4051885ab6713bda307b05a6d294c/untitled.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/My Drive/DLDatasets")
!ls

!git clone https://github.com/deepinsight/insightface.git

pip install pypandoc

#!/usr/bin/env python
import os
import io
import re
import shutil
import sys
from setuptools import setup, find_packages

def read(*names, **kwargs):
    with io.open(
        os.path.join(os.path.dirname('DLDatasets/insightface'), *names),
        encoding=kwargs.get("encoding", "utf8")
    ) as fp:
        return fp.read()


def find_version(*file_paths):
    version_file = read(*file_paths)
    version_match = re.search(r"^__version__ = ['\"]([^'\"]*)['\"]",
                              version_file, re.M)
    if version_match:
        return version_match.group(1)
    raise RuntimeError("Unable to find version string.")
from setuptools import setup

try:
  import pypandoc
  long_description = pypandoc.convert('/content/drive/My Drive/DLDatasets/insightface/python-package/README.md', 'rst')
except(IOError, ImportError):
   long_description = open('/content/drive/My Drive/DLDatasets/insightface/python-package/README.md').read()

VERSION = find_version('insightface', '__init__.py')

requirements = [
    'numpy',
    'tqdm',
    'requests',
    'matplotlib',
    'Pillow',
    'scipy',
    'opencv-python',
    'scikit-learn',
    'scikit-image',
    'easydict',
]

setup(
    # Metadata
    name='insightface',
    version=VERSION,
    author='InsightFace Contributors',
    url='https://github.com/deepinsight/insightface',
    description='InsightFace Toolkit',
    long_description=long_description,
    license='Apache-2.0',
    # Package info
    packages=find_packages(exclude=('docs', 'tests', 'scripts')),
    zip_safe=True,
    include_package_data=True,
    install_requires=requirements,
)

import numpy as np
from easydict import EasyDict as edict

config = edict()

#default training/dataset config
config.num_classes = 3
config.input_img_size = 256
config.output_label_size = 64

# network settings
network = edict()

network.hourglass = edict()
network.hourglass.net_sta = 0
network.hourglass.net_n = 4
network.hourglass.net_dcn = 0
network.hourglass.net_stacks = 1
network.hourglass.net_block = 'resnet'
network.hourglass.net_binarize = False
network.hourglass.losstype = 'heatmap'
network.hourglass.multiplier = 1.0

network.prnet = edict()
network.prnet.net_sta = 0
network.prnet.net_n = 5
network.prnet.net_dcn = 0
network.prnet.net_stacks = 1
network.prnet.net_modules = 2
network.prnet.net_block = 'hpm'
network.prnet.net_binarize = False
network.prnet.losstype = 'heatmap'
network.prnet.multiplier = 0.25

network.hpm = edict()
network.hpm.net_sta = 0
network.hpm.net_n = 4
network.hpm.net_dcn = 0
network.hpm.net_stacks = 1
network.hpm.net_block = 'hpm'
network.hpm.net_binarize = False
network.hpm.losstype = 'heatmap'
network.hpm.multiplier = 1.0


# dataset settings
dataset = edict()


dataset.prnet = edict()
dataset.prnet.dataset = '3D'
dataset.prnet.landmark_type = 'dense'
dataset.prnet.dataset_path = './data64'
dataset.prnet.num_classes = 3
dataset.prnet.input_img_size = 256
dataset.prnet.output_label_size = 64
#dataset.prnet.label_xfirst = False
dataset.prnet.val_targets = ['']

# default settings
default = edict()

# default network
default.network = 'hpm'
default.pretrained = ''
default.pretrained_epoch = 0
# default dataset
default.dataset = 'prnet'
default.frequent = 20
default.verbose = 200
default.kvstore = 'device'

default.prefix = 'model/A'
default.end_epoch = 10000
default.lr = 0.00025
default.wd = 0.0
default.per_batch_size = 20
default.lr_step = '16000,24000,30000'

def generate_config(_network, _dataset):
    for k, v in network[_network].items():
      config[k] = v
      default[k] = v
    for k, v in dataset[_dataset].items():
      config[k] = v
      default[k] = v
    config.network = _network
    config.dataset = _dataset

# pylint: skip-file
!pip install mxnet 

import mxnet as mx
import numpy as np
import sys, os
import random
import glob
import math
import scipy.misc
import cv2
import logging
import sklearn
import datetime
from pyquickhelper import imghelper
from mxnet.io import DataIter
from mxnet import ndarray as nd
from mxnet import io
from mxnet import recordio
from PIL import Image
import config
from skimage import transform as tf


class FaceSegIter(DataIter):
    def __init__(self, path, batch_size, 
                 per_batch_size = 0,
                 aug_level = 0,
                 force_mirror = False,
                 exf = 1,
                 args = None):
      self.aug_level = aug_level
      self.force_mirror = force_mirror
      self.exf = exf
      self.batch_size = batch_size
      self.per_batch_size = per_batch_size
      self.image_file_list = []
      self.uv_file_list = []
      for _file in glob.glob(os.path.join(path, '*.jpg')):
        self.image_file_list.append(_file)
      for img in self.image_file_list:
        uv_file = img[0:-3]+"npy"
        self.uv_file_list.append(uv_file)
      self.seq = range(len(self.image_file_list))
      print('train size', len(self.seq))
      self.cur = 0
      self.reset()
      self.data_shape = (3, config.input_img_size, config.input_img_size)
      self.num_classes = config.num_classes
      self.input_img_size = config.input_img_size
      #self.label_classes = self.num_classes
      self.output_label_size = config.output_label_size
      #if aug_level>0:
      #  self.output_label_size = config.output_label_size
      #else:
      #  self.output_label_size = self.input_img_size
      self.label_shape = (self.num_classes, self.output_label_size, self.output_label_size)
      self.provide_data = [('data', (batch_size,) + self.data_shape)]
      self.provide_label = [('softmax_label', (batch_size,) + self.label_shape),
                            ('mask_label', (batch_size,)+ self.label_shape)]
      weight_mask = cv2.imread('./uv-data/uv_weight_mask.png')
      print('weight_mask', weight_mask.shape)
      if weight_mask.shape[0]!=self.output_label_size:
        weight_mask = cv2.resize(weight_mask, (self.output_label_size, self.output_label_size) )
      #idx = np.where(weight_mask>0)[0]
      #print('weight idx', idx)
      weight_mask = weight_mask.astype(np.float32)
      weight_mask /= 255.0

      vis_mask = cv2.imread('./uv-data/uv_face_mask.png')
      print('vis_mask', vis_mask.shape)
      if vis_mask.shape[0]!=self.output_label_size:
        vis_mask = cv2.resize(vis_mask, (self.output_label_size, self.output_label_size) )
      vis_mask = vis_mask.astype(np.float32)
      vis_mask /= 255.0
      weight_mask *= vis_mask
      print('weight_mask', weight_mask.shape)
      weight_mask = weight_mask.transpose( (2,0,1) )
      #WM = np.zeros( (batch_size,)+self.label_shape, dtype=np.float32 )
      #for i in range(batch_size):
      #  WM[i] = weight_mask
      #weight_mask = WM
      #weight_mask = weight_mask.reshape( (1, 3, weight_mask.shape[0], weight_mask.shape[1]) )
      weight_mask = weight_mask[np.newaxis,:,:,:]
      print('weight_mask', weight_mask.shape)
      weight_mask = np.tile(weight_mask, (batch_size,1,1,1))
      print('weight_mask', weight_mask.shape)
      self.weight_mask = nd.array(weight_mask)
      self.img_num = 0
      self.invalid_num = 0
      self.mode = 1
      self.vis = 0
      self.stats = [0,0]

    def get_data_shape(self):
        return self.data_shape

    #def get_label_shape(self):
    #    return self.label_shape

    def get_shape_dict(self):
        D = {}
        for (k,v) in self.provide_data:
            D[k] = v
        for (k,v) in self.provide_label:
            D[k] = v
        return D

    def get_label_names(self):
        D = []
        for (k,v) in self.provide_label:
            D.append(k)
        return D

    def reset(self):
      #print('reset')
      self.cur = 0
      if self.aug_level>0:
        random.shuffle(self.seq)

    def next_sample(self):
      """Helper function for reading in next sample."""
      if self.cur >= len(self.seq):
        raise StopIteration
      idx = self.seq[self.cur]
      self.cur += 1
      uv_path = self.uv_file_list[idx]
      image_path = self.image_file_list[idx]
      uvmap = np.load(uv_path)
      img = cv2.imread(image_path)[:,:,::-1]#to rgb
      hlabel = uvmap
      #print(hlabel.shape)
      #hlabel = np.array(header.label).reshape( (self.output_label_size, self.output_label_size, self.num_classes) )
      hlabel /= self.input_img_size

      return img, hlabel


    def next(self):
        """Returns the next batch of data."""
        #print('next')
        batch_size = self.batch_size
        batch_data = nd.empty((batch_size,)+self.data_shape)
        batch_label = nd.empty((batch_size,)+self.label_shape)
        i = 0
        #self.cutoff = random.randint(800,1280)
        try:
            while i < batch_size:
                #print('N', i)
                data, label = self.next_sample()
                data = nd.array(data)
                data = nd.transpose(data, axes=(2, 0, 1))
                label = nd.array(label)
                label = nd.transpose(label, axes=(2, 0, 1))
                batch_data[i][:] = data
                batch_label[i][:] = label
                i += 1
        except StopIteration:
            if i<batch_size:
                raise StopIteration

        #return {self.data_name  :  batch_data,
        #        self.label_name :  batch_label}
        #print(batch_data.shape, batch_label.shape)
        return mx.io.DataBatch([batch_data], [batch_label, self.weight_mask], batch_size - i)

!pip install config

!pip install pyquickhelper

import mxnet as mx
import numpy as np
import math
import cv2
import config

class LossValueMetric(mx.metric.EvalMetric):
  def __init__(self):
    self.axis = 1
    super(LossValueMetric, self).__init__(
        'lossvalue', axis=self.axis,
        output_names=None, label_names=None)
    self.losses = []

  def update(self, labels, preds):
    loss = preds[0].asnumpy()
    self.sum_metric += np.mean(loss)
    self.num_inst += 1.0

class NMEMetric(mx.metric.EvalMetric):
  def __init__(self):
    self.axis = 1
    super(NMEMetric, self).__init__(
        'NME', axis=self.axis,
        output_names=None, label_names=None)
    #self.losses = []
    self.count = 0

  def cal_nme(self, label, pred_label):
    nme = []
    for b in xrange(pred_label.shape[0]):
      record = [None]*6
      item = []
      if label.ndim==4:
          _heatmap = label[b][36]
          if np.count_nonzero(_heatmap)==0:
              continue
      else:#ndim==3
          #print(label[b])
          if np.count_nonzero(label[b])==0:
              continue
      for p in xrange(pred_label.shape[1]):
        if label.ndim==4:
            heatmap_gt = label[b][p]
            ind_gt = np.unravel_index(np.argmax(heatmap_gt, axis=None), heatmap_gt.shape)
            ind_gt = np.array(ind_gt)
        else:
            ind_gt = label[b][p]
            #ind_gt = ind_gt.astype(np.int)
            #print(ind_gt)
        heatmap_pred = pred_label[b][p]
        heatmap_pred = cv2.resize(heatmap_pred, (config.input_img_size, config.input_img_size))
        ind_pred = np.unravel_index(np.argmax(heatmap_pred, axis=None), heatmap_pred.shape)
        ind_pred = np.array(ind_pred)
        #print(ind_gt.shape)
        #print(ind_pred)
        if p==36:
            #print('b', b, p, ind_gt, np.count_nonzero(heatmap_gt))
            record[0] = ind_gt
        elif p==39:
            record[1] = ind_gt
        elif p==42:
            record[2] = ind_gt
        elif p==45:
            record[3] = ind_gt
        if record[4] is None or record[5] is None:
            record[4] = ind_gt
            record[5] = ind_gt
        else:
            record[4] = np.minimum(record[4], ind_gt)
            record[5] = np.maximum(record[5], ind_gt)
        #print(ind_gt.shape, ind_pred.shape)
        value = np.sqrt(np.sum(np.square(ind_gt - ind_pred)))
        item.append(value)
      _nme = np.mean(item)
      if config.landmark_type=='2d':
          left_eye = (record[0]+record[1])/2
          right_eye = (record[2]+record[3])/2
          _dist = np.sqrt(np.sum(np.square(left_eye - right_eye)))
          #print('eye dist', _dist, left_eye, right_eye)
          _nme /= _dist
      else:
          #_dist = np.sqrt(float(label.shape[2]*label.shape[3]))
          _dist = np.sqrt(np.sum(np.square(record[5] - record[4])))
          #print(_dist)
          _nme /= _dist
      nme.append(_nme)
    return np.mean(nme)

  def update(self, labels, preds):
    self.count+=1
    label = labels[0].asnumpy()
    pred_label = preds[-1].asnumpy()
    nme = self.cal_nme(label, pred_label)

    #print('nme', nme)
    #nme = np.mean(nme)
    self.sum_metric += np.mean(nme)
    self.num_inst += 1.0

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import logging
import argparse
import FaceSegIter
import mxnet as mx
import mxnet.optimizer as optimizer
import numpy as np
import os
import sys
import math
import random
import cv2
from config import config, default, generate_config
from optimizer import ONadam
from metric import LossValueMetric, NMEMetric
sys.path.append(os.path.join(os.path.dirname(__file__), 'symbol'))
import sym_heatmap
#import sym_fc
#from symbol import fc


args = None
logger = logging.getLogger()
logger.setLevel(logging.INFO)


def main(args):
  _seed = 727
  random.seed(_seed)
  np.random.seed(_seed)
  mx.random.seed(_seed)
  ctx = []
  cvd = os.environ['CUDA_VISIBLE_DEVICES'].strip()
  if len(cvd)>0:
    for i in xrange(len(cvd.split(','))):
      ctx.append(mx.gpu(i))
  if len(ctx)==0:
    ctx = [mx.cpu()]
    print('use cpu')
  else:
    print('gpu num:', len(ctx))
  #ctx = [mx.gpu(0)]
  args.ctx_num = len(ctx)

  args.batch_size = args.per_batch_size*args.ctx_num
  config.per_batch_size = args.per_batch_size



  print('Call with', args, config)
  train_iter = FaceSegIter(path = config.dataset_path,
      batch_size = args.batch_size,
      per_batch_size = args.per_batch_size,
      aug_level = 1,
      exf = args.exf,
      args = args,
      )

  data_shape = train_iter.get_data_shape()
  #label_shape = train_iter.get_label_shape()
  sym = sym_heatmap.get_symbol(num_classes=config.num_classes)
  if len(args.pretrained)==0:
      #data_shape_dict = {'data' : (args.per_batch_size,)+data_shape, 'softmax_label' : (args.per_batch_size,)+label_shape}
      data_shape_dict = train_iter.get_shape_dict()
      arg_params, aux_params = sym_heatmap.init_weights(sym, data_shape_dict)
  else:
      vec = args.pretrained.split(',')
      print('loading', vec)
      _, arg_params, aux_params = mx.model.load_checkpoint(vec[0], int(vec[1]))
      #sym, arg_params, aux_params = get_symbol(args, arg_params, aux_params)

  model = mx.mod.Module(
      context       = ctx,
      symbol        = sym,
      label_names   = train_iter.get_label_names(),
  )
  #lr = 1.0e-3
  #lr = 2.5e-4
  #_rescale_grad = 1.0/args.ctx_num
  _rescale_grad = 1.0/args.batch_size
  #lr = args.lr
  #opt = optimizer.Nadam(learning_rate=args.lr, wd=args.wd, rescale_grad=_rescale_grad, clip_gradient=5.0)
  if args.optimizer=='onadam':
    opt = ONadam(learning_rate=args.lr, wd=args.wd, rescale_grad=_rescale_grad, clip_gradient=5.0)
  elif args.optimizer=='nadam':
    opt = optimizer.Nadam(learning_rate=args.lr, rescale_grad=_rescale_grad)
  elif args.optimizer=='rmsprop':
    opt = optimizer.RMSProp(learning_rate=args.lr, rescale_grad=_rescale_grad)
  elif args.optimizer=='adam':
    opt = optimizer.Adam(learning_rate=args.lr, rescale_grad=_rescale_grad)
  else:
    opt = optimizer.SGD(learning_rate=args.lr, momentum=0.9, wd=args.wd, rescale_grad=_rescale_grad)
  initializer = mx.init.Xavier(rnd_type='gaussian', factor_type="in", magnitude=2)
  _cb = mx.callback.Speedometer(args.batch_size, args.frequent)
  _metric = LossValueMetric()
  #_metric = NMEMetric()
  #_metric2 = AccMetric()
  #eval_metrics = [_metric, _metric2]
  eval_metrics = [_metric]
  lr_steps = [int(x) for x in args.lr_step.split(',')]
  print('lr-steps', lr_steps)
  global_step = [0]

  def val_test():
    all_layers = sym.get_internals()
    vsym = all_layers['heatmap_output']
    vmodel = mx.mod.Module(symbol=vsym, context=ctx, label_names = None)
    #model.bind(data_shapes=[('data', (args.batch_size, 3, image_size[0], image_size[1]))], label_shapes=[('softmax_label', (args.batch_size,))])
    vmodel.bind(data_shapes=[('data', (args.batch_size,)+data_shape)])
    arg_params, aux_params = model.get_params()
    vmodel.set_params(arg_params, aux_params)
    for target in config.val_targets:
        _file = os.path.join(config.dataset_path, '%s.rec'%target)
        if not os.path.exists(_file):
            continue
        val_iter = FaceSegIter(path_imgrec = _file,
          batch_size = args.batch_size,
          #batch_size = 4,
          aug_level = 0,
          args = args,
          )
        _metric = LossValueMetric()
        val_metric = mx.metric.create(_metric)
        val_metric.reset()
        val_iter.reset()
        diffs = []
        for i, eval_batch in enumerate(val_iter):
          #print(eval_batch.data[0].shape, eval_batch.label[0].shape)
          batch_data = mx.io.DataBatch(eval_batch.data)
          model.forward(batch_data, is_train=False)
          _label = eval_batch.label[0].asnumpy()
          _pred = model.get_outputs()[-1].asnumpy()
          _diff = np.abs(_pred-_label)
          _diff = np.mean(_diff)*config.input_img_size
          #print('pred', _pred.shape, _label.shape)
          #print('diff', _diff)
          diffs.append(_diff)
          model.update_metric(val_metric, eval_batch.label)
        nme_value = val_metric.get_name_value()[0][1]
        print('[%d][%s]LOSS: %f'%(global_step[0], target, nme_value))
        print('avg diff', np.mean(diffs))
  
  def _batch_callback(param):
    _cb(param)
    global_step[0]+=1
    mbatch = global_step[0]
    for _lr in lr_steps:
      if mbatch==_lr:
        if args.optimizer=='sgd':
          opt.lr *= 0.1
        else:
          opt.lr *= 0.5
        print('lr change to', opt.lr)
        break
    if mbatch%1000==0:
      print('lr-batch-epoch:',opt.lr,param.nbatch,param.epoch)
    if mbatch>0 and mbatch%args.verbose==0:
      val_test()
      if args.ckpt==1:
        msave = mbatch//args.verbose
        print('saving', msave)
        arg, aux = model.get_params()
        mx.model.save_checkpoint(args.prefix, msave, model.symbol, arg, aux)
    if mbatch==lr_steps[-1]:
      if args.ckpt==2:
        #msave = mbatch//args.verbose
        msave = 1
        print('saving', msave)
        arg, aux = model.get_params()
        mx.model.save_checkpoint(args.prefix, msave, model.symbol, arg, aux)
      sys.exit(0)

  train_iter = mx.io.PrefetchingIter(train_iter)

  model.fit(train_iter,
      begin_epoch        = 0,
      num_epoch          = 9999,
      #eval_data          = val_iter,
      eval_data          = None,
      eval_metric        = eval_metrics,
      kvstore            = 'device',
      optimizer          = opt,
      initializer        = initializer,
      arg_params         = arg_params,
      aux_params         = aux_params,
      allow_missing      = True,
      batch_end_callback = _batch_callback,
      epoch_end_callback = None,
      )

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description='Train face alignment')
  # general
  parser.add_argument('--network', help='network name', default=default.network, type=str)
  parser.add_argument('--dataset', help='dataset name', default=default.dataset, type=str)
  args, rest = parser.parse_known_args()
  generate_config(args.network, args.dataset)
  parser.add_argument('--prefix', default=default.prefix, help='directory to save model.')
  parser.add_argument('--pretrained', default=default.pretrained, help='')
  parser.add_argument('--optimizer', default='nadam', help='')
  parser.add_argument('--lr', type=float, default=default.lr, help='')
  parser.add_argument('--wd', type=float, default=default.wd, help='')
  parser.add_argument('--per-batch-size', type=int, default=default.per_batch_size, help='')
  parser.add_argument('--lr-step', help='learning rate steps (in epoch)', default=default.lr_step, type=str)
  parser.add_argument('--ckpt', type=int, default=1, help='')
  parser.add_argument('--norm', type=int, default=0, help='')
  parser.add_argument('--exf', type=int, default=1, help='')
  parser.add_argument('--frequent', type=int, default=default.frequent, help='')
  parser.add_argument('--verbose', type=int, default=default.verbose, help='')
  args = parser.parse_args()
  main(args)

!pip install insightface

# pylint: skip-file
import mxnet as mx
import numpy as np
import sys, os
import random
import math
import scipy.misc
import cv2
import logging
import sklearn
import datetime
from pyquickhelper import imghelper
from mxnet.io import DataIter
from mxnet import ndarray as nd
from mxnet import io
from mxnet import recordio
from PIL import Image
import config
from skimage import transform as tf

class FaceSegIter(DataIter):
    def __init__(self, batch_size, 
                 per_batch_size = 0,
                 path_imgrec = None,
                 aug_level = 0,
                 force_mirror = False,
                 exf = 1,
                 use_coherent = 0,
                 args = None,
                 data_name = "data",
                 label_name = "softmax_label"):
      self.aug_level = aug_level
      self.force_mirror = force_mirror
      self.use_coherent = use_coherent
      self.exf = exf
      self.batch_size = batch_size
      self.per_batch_size = per_batch_size
      self.data_name = data_name
      self.label_name = label_name
      assert path_imgrec
      logging.info('loading recordio %s...',
                   path_imgrec)
      path_imgidx = path_imgrec[0:-4]+".idx"
      self.imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, 'r')  # pylint: disable=redefined-variable-type
      self.oseq = list(self.imgrec.keys)
      print('train size', len(self.oseq))
      self.cur = 0
      self.reset()
      self.data_shape = (3, config.input_img_size, config.input_img_size)
      self.num_classes = config.num_classes
      self.input_img_size = config.input_img_size
      #self.label_classes = self.num_classes
      if config.losstype=='heatmap':
        if aug_level>0:
          self.output_label_size = config.output_label_size
          self.label_shape = (self.num_classes, self.output_label_size, self.output_label_size)
        else:
          self.output_label_size = self.input_img_size
          #self.label_shape = (self.num_classes, 2)
          self.label_shape = (self.num_classes, self.output_label_size, self.output_label_size)
      else:
        if aug_level>0:
          self.output_label_size = config.output_label_size
          self.label_shape = (self.num_classes, 2)
        else:
          self.output_label_size = self.input_img_size
          #self.label_shape = (self.num_classes, 2)
          self.label_shape = (self.num_classes, 2)
      self.provide_data = [(data_name, (batch_size,) + self.data_shape)]
      self.provide_label = [(label_name, (batch_size,) + self.label_shape)]
      self.img_num = 0
      self.invalid_num = 0
      self.mode = 1
      self.vis = 0
      self.stats = [0,0]
      self.flip_order = [16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 
          26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 27, 28, 29, 30, 35, 34, 33, 32, 31, 
          45, 44, 43, 42, 47, 46, 39, 38, 37, 36, 41, 40, 54, 53, 52, 51, 50, 49, 48, 
          59, 58, 57, 56, 55, 64, 63, 62, 61, 60, 67, 66, 65]
      #self.mirror_set = [
      #        (22,23),
      #        (21,24),
      #        (20,25),
      #        (19,26),
      #        (18,27),
      #        (40,43),
      #        (39,44),
      #        (38,45),
      #        (37,46),
      #        (42,47),
      #        (41,48),
      #        (33,35),
      #        (32,36),
      #        (51,53),
      #        (50,54),
      #        (62,64),
      #        (61,65),
      #        (49,55),
      #        (49,55),
      #        (68,66),
      #        (60,56),
      #        (59,57),
      #        (1,17),
      #        (2,16),
      #        (3,15),
      #        (4,14),
      #        (5,13),
      #        (6,12),
      #        (7,11),
      #        (8,10),
      #    ]

    def get_data_shape(self):
        return self.data_shape

    #def get_label_shape(self):
    #    return self.label_shape

    def get_shape_dict(self):
        D = {}
        for (k,v) in self.provide_data:
            D[k] = v
        for (k,v) in self.provide_label:
            D[k] = v
        return D

    def get_label_names(self):
        D = []
        for (k,v) in self.provide_label:
            D.append(k)
        return D

    def reset(self):
      #print('reset')
      if self.aug_level==0:
        self.seq = self.oseq
      else:
        self.seq = []
        for _ in range(self.exf):
          _seq = self.oseq[:]
          random.shuffle(_seq)
          self.seq += _seq
        print('train size after reset', len(self.seq))
      self.cur = 0

    def next_sample(self):
      """Helper function for reading in next sample."""
      if self.cur >= len(self.seq):
        raise StopIteration
      idx = self.seq[self.cur]
      self.cur += 1
      s = self.imgrec.read_idx(idx)
      header, img = recordio.unpack(s)
      img = mx.image.imdecode(img).asnumpy()
      hlabel = np.array(header.label).reshape( (self.num_classes,2) )
      if not config.label_xfirst:
        hlabel = hlabel[:,::-1] #convert to X/W first
      annot = {'scale': config.base_scale}

      #ul = np.array( (50000,50000), dtype=np.int32)
      #br = np.array( (0,0), dtype=np.int32)
      #for i in range(hlabel.shape[0]):
      #  h = int(hlabel[i][0])
      #  w = int(hlabel[i][1])
      #  key = np.array((h,w))
      #  ul = np.minimum(key, ul)
      #  br = np.maximum(key, br)

      return img, hlabel, annot

    def get_flip(self, data, label):
      data_flip = np.zeros_like(data)
      label_flip = np.zeros_like(label)
      for k in range(data_flip.shape[2]):
          data_flip[:,:,k] = np.fliplr(data[:,:,k])
      for k in range(label_flip.shape[0]):
          label_flip[k,:] = np.fliplr(label[k,:])
      #print(label[0,:].shape)
      label_flip = label_flip[self.flip_order,:]
      return data_flip, label_flip

    def get_data(self, data, label, annot):
      if self.vis:
        self.img_num+=1
        #if self.img_num<=self.vis:
        #  filename = './vis/raw_%d.jpg' % (self.img_num)
        #  print('save', filename)
        #  draw = data.copy()
        #  for i in range(label.shape[0]):
        #    cv2.circle(draw, (label[i][1], label[i][0]), 1, (0, 0, 255), 2)
        #  scipy.misc.imsave(filename, draw)

      rotate = 0
      #scale = 1.0
      if 'scale' in annot:
          scale = annot['scale']
      else:
          scale = max(data.shape[0], data.shape[1])
      if 'center' in annot:
        center = annot['center']
      else:
        center = np.array( (data.shape[1]/2, data.shape[0]/2) )
      max_retry = 3
      if self.aug_level==0: #validation mode
          max_retry = 6
      retry = 0
      found = False
      base_scale = scale
      while retry<max_retry:
          retry+=1
          succ = True
          _scale = base_scale
          if self.aug_level>0:
            rotate = np.random.randint(-40, 40)
            scale_config = 0.2
            #rotate = 0
            #scale_config = 0.0
            scale_ratio = min(1+scale_config, max(1-scale_config, (np.random.randn() * scale_config) + 1))
            _scale = int(base_scale * scale_ratio)
            #translate = np.random.randint(-5, 5, size=(2,))
            #center += translate
          data_out, trans = img_helper.transform(data, center, self.input_img_size, _scale, rotate)
          #data_out = img_helper.crop2(data, center, _scale, (self.input_img_size, self.input_img_size), rot=rotate)
          label_out = np.zeros(self.label_shape, dtype=np.float32)
          #print('out shapes', data_out.shape, label_out.shape)
          for i in range(label.shape[0]):
            pt = label[i].copy()
            #pt = pt[::-1]
            npt = img_helper.transform_pt(pt, trans)
            if npt[0]>=data_out.shape[1] or npt[1]>=data_out.shape[0] or npt[0]<0 or npt[1]<0:
              succ = False
              #print('err npt', npt)
              break
            if config.losstype=='heatmap':
              pt_scale = float(self.output_label_size)/self.input_img_size
              npt *= pt_scale
              npt = npt.astype(np.int32)
              img_helper.gaussian(label_out[i], npt, config.gaussian)
            else:
              label_out[i] = (npt/self.input_img_size)
            #print('before gaussian', label_out[i].shape, pt.shape)
            #trans = img_helper.transform(pt, center, _scale, (self.output_label_size, self.output_label_size), rot=rotate)
            #print(trans.shape)
            #if not img_helper.gaussian(label_out[i], trans, _g):
            #    succ = False
            #    break
          if not succ:
              if self.aug_level==0:
                  base_scale+=20
              continue
          
          flip_data_out = None
          flip_label_out = None
          if config.net_coherent:
            flip_data_out, flip_label_out = self.get_flip(data_out, label_out)
          elif ((self.aug_level>0 and np.random.rand() < 0.5) or self.force_mirror): #flip aug
            flip_data_out, flip_label_out = self.get_flip(data_out, label_out)
            data_out, label_out = flip_data_out, flip_label_out

          found = True
          break


      #self.stats[0]+=1
      if not found:
          #self.stats[1]+=1
          #print('find aug error', retry)
          #print(self.stats)
          #print('!!!ERR')
          return None
      #print('found with scale', _scale, rotate)


      if self.vis>0 and self.img_num<=self.vis:
        print('crop', data.shape, center, _scale, rotate, data_out.shape)
        filename = './vis/cropped_%d.jpg' % (self.img_num)
        print('save', filename)
        draw = data_out.copy()
        alabel = label_out.copy()
        for i in range(label.shape[0]):
          a = cv2.resize(alabel[i], (self.input_img_size, self.input_img_size))
          ind = np.unravel_index(np.argmax(a, axis=None), a.shape)
          cv2.circle(draw, (ind[1], ind[0]), 1, (0, 0, 255), 2)
        scipy.misc.imsave(filename, draw)
        filename = './vis/raw_%d.jpg' % (self.img_num)
        scipy.misc.imsave(filename, data)

      return data_out, label_out, flip_data_out,flip_label_out 

    def next(self):
        """Returns the next batch of data."""
        #print('next')
        batch_size = self.batch_size
        batch_data = nd.empty((batch_size,)+self.data_shape)
        batch_label = nd.empty((batch_size,)+self.label_shape)
        i = 0
        #self.cutoff = random.randint(800,1280)
        try:
            while i < batch_size:
                #print('N', i)
                data, label, annot = self.next_sample()
                R = self.get_data(data, label, annot)
                if R is None:
                  continue
                data_out, label_out, flip_data_out, flip_label_out = R
                if not self.use_coherent:
                    data = nd.array(data_out)
                    data = nd.transpose(data, axes=(2, 0, 1))
                    label = nd.array(label_out)
                    #print(data.shape, label.shape)
                    batch_data[i][:] = data
                    batch_label[i][:] = label
                    i += 1
                else:
                    data = nd.array(data_out)
                    data = nd.transpose(data, axes=(2, 0, 1))
                    label = nd.array(label_out)
                    data2 = nd.array(flip_data_out)
                    data2 = nd.transpose(data2, axes=(2, 0, 1))
                    label2 = nd.array(flip_label_out)
                    #M = nd.array(M)
                    #print(data.shape, label.shape)
                    batch_data[i][:] = data
                    batch_label[i][:] = label
                    #i+=1
                    j = i+self.per_batch_size//2
                    batch_data[j][:] = data2
                    batch_label[j][:] = label2
                    i += 1
                    if j%self.per_batch_size==self.per_batch_size-1:
                        i = j+1
        except StopIteration:
            if i<batch_size:
                raise StopIteration

        #return {self.data_name  :  batch_data,
        #        self.label_name :  batch_label}
        #print(batch_data.shape, batch_label.shape)
        return mx.io.DataBatch([batch_data], [batch_label], batch_size - i)

!pip install data

import numpy as np
import math
import cv2
from skimage import transform as stf

def transform(data, center, output_size, scale, rotation):
    scale_ratio = float(output_size)/scale
    rot = float(rotation)*np.pi/180.0
    #translation = (output_size/2-center[0]*scale_ratio, output_size/2-center[1]*scale_ratio)
    t1 = stf.SimilarityTransform(scale=scale_ratio)
    cx = center[0]*scale_ratio
    cy = center[1]*scale_ratio
    t2 = stf.SimilarityTransform(translation=(-1*cx, -1*cy))
    t3 = stf.SimilarityTransform(rotation=rot)
    t4 = stf.SimilarityTransform(translation=(output_size/2, output_size/2))
    t = t1+t2+t3+t4
    trans = t.params[0:2]
    #print('M', scale, rotation, trans)
    cropped = cv2.warpAffine(data,trans,(output_size, output_size), borderValue = 0.0)
    return cropped, trans

def transform_pt(pt, trans):
    new_pt = np.array([pt[0], pt[1], 1.]).T
    new_pt = np.dot(trans, new_pt)
    #print('new_pt', new_pt.shape, new_pt)
    return new_pt[:2]

def gaussian(img, pt, sigma):
    # Draw a 2D gaussian
    assert(sigma>=0)
    if sigma==0:
      img[pt[1], pt[0]] = 1.0
      return True
    #assert pt[0]<=img.shape[1]
    #assert pt[1]<=img.shape[0]

    # Check that any part of the gaussian is in-bounds
    ul = [int(pt[0] - 3 * sigma), int(pt[1] - 3 * sigma)]
    br = [int(pt[0] + 3 * sigma + 1), int(pt[1] + 3 * sigma + 1)]
    if (ul[0] > img.shape[1] or ul[1] >= img.shape[0] or
            br[0] < 0 or br[1] < 0):
        # If not, just return the image as is
        #print('gaussian error')
        return False
        #return img

    # Generate gaussian
    size = 6 * sigma + 1
    x = np.arange(0, size, 1, float)
    y = x[:, np.newaxis]
    x0 = y0 = size // 2
    # The gaussian is not normalized, we want the center value to equal 1
    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))

    # Usable gaussian range
    g_x = max(0, -ul[0]), min(br[0], img.shape[1]) - ul[0]
    g_y = max(0, -ul[1]), min(br[1], img.shape[0]) - ul[1]
    # Image range
    img_x = max(0, ul[0]), min(br[0], img.shape[1])
    img_y = max(0, ul[1]), min(br[1], img.shape[0])

    img[img_y[0]:img_y[1], img_x[0]:img_x[1]] = g[g_y[0]:g_y[1], g_x[0]:g_x[1]]
    return True
    #return img

def estimate_trans_bbox(face, input_size, s = 2.0):
  w = face[2] - face[0]
  h = face[3] - face[1]
  wc = int( (face[2]+face[0])/2 )
  hc = int( (face[3]+face[1])/2 )
  im_size = max(w, h)
  #size = int(im_size*1.2)
  scale = input_size/(max(w,h)*s)
  M = [ 
        [scale, 0, input_size/2-wc*scale],
        [0, scale, input_size/2-hc*scale],
      ]
  M = np.array(M)
  return M

import mxnet as mx
import numpy as np
import math
import cv2
import config

class LossValueMetric(mx.metric.EvalMetric):
  def __init__(self):
    self.axis = 1
    super(LossValueMetric, self).__init__(
        'lossvalue', axis=self.axis,
        output_names=None, label_names=None)
    self.losses = []

  def update(self, labels, preds):
    loss = preds[0].asnumpy()[0]
    self.sum_metric += loss
    self.num_inst += 1.0

class NMEMetric(mx.metric.EvalMetric):
  def __init__(self):
    self.axis = 1
    super(NMEMetric, self).__init__(
        'NME', axis=self.axis,
        output_names=None, label_names=None)
    #self.losses = []
    self.count = 0

  def cal_nme(self, label, pred_label):
    nme = []
    for b in range(pred_label.shape[0]):
      record = [None]*6
      item = []
      if label.ndim==4:
          _heatmap = label[b][36]
          if np.count_nonzero(_heatmap)==0:
              continue
      else:#ndim==3
          #print(label[b])
          if np.count_nonzero(label[b])==0:
              continue
      for p in range(pred_label.shape[1]):
        if label.ndim==4:
            heatmap_gt = label[b][p]
            ind_gt = np.unravel_index(np.argmax(heatmap_gt, axis=None), heatmap_gt.shape)
            ind_gt = np.array(ind_gt)
        else:
            ind_gt = label[b][p]
            #ind_gt = ind_gt.astype(np.int)
            #print(ind_gt)
        heatmap_pred = pred_label[b][p]
        heatmap_pred = cv2.resize(heatmap_pred, (config.input_img_size, config.input_img_size))
        ind_pred = np.unravel_index(np.argmax(heatmap_pred, axis=None), heatmap_pred.shape)
        ind_pred = np.array(ind_pred)
        #print(ind_gt.shape)
        #print(ind_pred)
        if p==36:
            #print('b', b, p, ind_gt, np.count_nonzero(heatmap_gt))
            record[0] = ind_gt
        elif p==39:
            record[1] = ind_gt
        elif p==42:
            record[2] = ind_gt
        elif p==45:
            record[3] = ind_gt
        if record[4] is None or record[5] is None:
            record[4] = ind_gt
            record[5] = ind_gt
        else:
            record[4] = np.minimum(record[4], ind_gt)
            record[5] = np.maximum(record[5], ind_gt)
        #print(ind_gt.shape, ind_pred.shape)
        value = np.sqrt(np.sum(np.square(ind_gt - ind_pred)))
        item.append(value)
      _nme = np.mean(item)
      if config.landmark_type=='2d':
          left_eye = (record[0]+record[1])/2
          right_eye = (record[2]+record[3])/2
          _dist = np.sqrt(np.sum(np.square(left_eye - right_eye)))
          #print('eye dist', _dist, left_eye, right_eye)
          _nme /= _dist
      else:
          #_dist = np.sqrt(float(label.shape[2]*label.shape[3]))
          _dist = np.sqrt(np.sum(np.square(record[5] - record[4])))
          #print(_dist)
          _nme /= _dist
      nme.append(_nme)
    return np.mean(nme)

  def update(self, labels, preds):
    self.count+=1
    label = labels[0].asnumpy()
    pred_label = preds[-1].asnumpy()
    nme = self.cal_nme(label, pred_label)

    #print('nme', nme)
    #nme = np.mean(nme)
    self.sum_metric += np.mean(nme)
    self.num_inst += 1.0

import mxnet as mx
import mxnet.optimizer as optimizer
from mxnet.ndarray import (NDArray, zeros, clip, sqrt, cast, maximum, abs as NDabs)
#from mxnet.ndarray import (sgd_update, sgd_mom_update, adam_update, rmsprop_update, rmspropalex_update,
#                      mp_sgd_update, mp_sgd_mom_update, square, ftrl_update)

class ONadam(optimizer.Optimizer):
    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8,
                 schedule_decay=0.004, **kwargs):
        super(ONadam, self).__init__(learning_rate=learning_rate, **kwargs)
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.schedule_decay = schedule_decay
        self.m_schedule = 1.

    def create_state(self, index, weight):
        return (zeros(weight.shape, weight.context, dtype=weight.dtype),  # mean
                zeros(weight.shape, weight.context, dtype=weight.dtype))  # variance

    def update(self, index, weight, grad, state):
        assert(isinstance(weight, NDArray))
        assert(isinstance(grad, NDArray))
        self._update_count(index)
        lr = self._get_lr(index)
        wd = self._get_wd(index)

        t = self._index_update_count[index]

        # preprocess grad
        #grad = grad * self.rescale_grad + wd * weight
        grad *= self.rescale_grad + wd * weight
        if self.clip_gradient is not None:
            grad = clip(grad, -self.clip_gradient, self.clip_gradient)

        # warming momentum schedule
        momentum_t = self.beta1 * (1. - 0.5 * (pow(0.96, t * self.schedule_decay)))
        momentum_t_1 = self.beta1 * (1. - 0.5 * (pow(0.96, (t + 1) * self.schedule_decay)))
        self.m_schedule = self.m_schedule * momentum_t
        m_schedule_next = self.m_schedule * momentum_t_1

        # update m_t and v_t
        m_t, v_t = state
        m_t[:] = self.beta1 * m_t + (1. - self.beta1) * grad
        v_t[:] = self.beta2 * v_t + (1. - self.beta2) * grad * grad

        grad_prime = grad / (1. - self.m_schedule)
        m_t_prime = m_t / (1. - m_schedule_next)
        v_t_prime = v_t / (1. - pow(self.beta2, t))
        m_t_bar = (1. - momentum_t) * grad_prime + momentum_t_1 * m_t_prime

        # update weight
        weight[:] -= lr * m_t_bar / (sqrt(v_t_prime) + self.epsilon)

import numpy as np
from easydict import EasyDict as edict

config = edict()

#default training/dataset config
config.num_classes = 68
config.record_img_size = 384
config.base_scale = 256
config.input_img_size = 128
config.output_label_size = 64
config.label_xfirst = False
config.losstype = 'heatmap'
config.net_coherent = False
config.multiplier = 1.0

config.gaussian = 0

# network settings
network = edict()

network.hourglass = edict()
network.hourglass.net_coherent = False
network.hourglass.net_sta = 0
network.hourglass.net_n = 3
network.hourglass.net_dcn = 0
network.hourglass.net_stacks = 2
network.hourglass.net_block = 'resnet'
network.hourglass.net_binarize = False
network.hourglass.losstype = 'heatmap'

network.sdu = edict()
network.sdu.net_coherent = False
network.sdu.net_sta = 1
network.sdu.net_n = 3
network.sdu.net_dcn = 3
network.sdu.net_stacks = 2
network.sdu.net_block = 'cab'
network.sdu.net_binarize = False
network.sdu.losstype = 'heatmap'


# dataset settings
dataset = edict()

dataset.i2d = edict()
dataset.i2d.dataset = '2D'
dataset.i2d.landmark_type = '2d'
dataset.i2d.dataset_path = './data_2d'
dataset.i2d.num_classes = 68
dataset.i2d.record_img_size = 384
dataset.i2d.base_scale = 256
dataset.i2d.input_img_size = 128
dataset.i2d.output_label_size = 64
dataset.i2d.label_xfirst = False
dataset.i2d.val_targets = ['ibug', 'cofw_testset', '300W']

dataset.i3d = edict()
dataset.i3d.dataset = '3D'
dataset.i3d.landmark_type = '3d'
dataset.i3d.dataset_path = './data_3d'
dataset.i3d.num_classes = 68
dataset.i3d.record_img_size = 384
dataset.i3d.base_scale = 256
dataset.i3d.input_img_size = 128
dataset.i3d.output_label_size = 64
dataset.i3d.label_xfirst = False
dataset.i3d.val_targets = ['AFLW2000-3D']


# default settings
default = edict()

# default network
default.network = 'hourglass'
default.pretrained = ''
default.pretrained_epoch = 0
# default dataset
default.dataset = 'i2d'
default.frequent = 20
default.verbose = 200
default.kvstore = 'device'

default.prefix = 'model/A'
default.end_epoch = 10000
default.lr = 0.00025
default.wd = 0.0
default.per_batch_size = 20
default.lr_step = '16000,24000,30000'

def generate_config(_network, _dataset):
    for k, v in network[_network].items():
      config[k] = v
      default[k] = v
    for k, v in dataset[_dataset].items():
      config[k] = v
      default[k] = v
    config.network = _network
    config.dataset = _dataset

import argparse
import cv2
import sys
import numpy as np
import os
import mxnet as mx
import datetime
from pyquickhelper import imghelper
import config
import FaceSegIter
from metric import LossValueMetric, NMEMetric

parser = argparse.ArgumentParser(description='test nme on rec data')
# general
parser.add_argument('--rec', default='./data_2d/ibug.rec', help='rec data path')
parser.add_argument('--prefix', default='', help='model prefix')
parser.add_argument('--epoch', type=int, default=1, help='model epoch')
parser.add_argument('--gpu', type=int, default=0, help='')
parser.add_argument('--landmark-type', default='2d', help='')
parser.add_argument('--image-size', type=int, default=128, help='')
args = parser.parse_args()

rec_path = args.rec
ctx_id = args.gpu
prefix = args.prefix
epoch = args.epoch
image_size = (args.image_size, args.image_size)
config.landmark_type = args.landmark_type
config.input_img_size = image_size[0]

if ctx_id>=0:
  ctx = mx.gpu(ctx_id)
else:
  ctx = mx.cpu()
sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)
all_layers = sym.get_internals()
sym = all_layers['heatmap_output']
#model = mx.mod.Module(symbol=sym, context=ctx, data_names=['data'], label_names=['softmax_label'])
model = mx.mod.Module(symbol=sym, context=ctx, data_names=['data'], label_names=None)
#model = mx.mod.Module(symbol=sym, context=ctx)
model.bind(for_training=False, data_shapes=[('data', (1, 3, image_size[0], image_size[1]))])
model.set_params(arg_params, aux_params)

val_iter = FaceSegIter(path_imgrec = rec_path,
  batch_size = 1,
  aug_level = 0,
  )
_metric = NMEMetric()
#val_metric = mx.metric.create(_metric)
#val_metric.reset()
#val_iter.reset()
nme = []
for i, eval_batch in enumerate(val_iter):
  if i%10==0:
    print('processing', i)
  #print(eval_batch.data[0].shape, eval_batch.label[0].shape)
  batch_data = mx.io.DataBatch(eval_batch.data)
  model.forward(batch_data, is_train=False)
  #model.update_metric(val_metric, eval_batch.label, True)
  pred_label = model.get_outputs()[-1].asnumpy()
  label = eval_batch.label[0].asnumpy()
  _nme = _metric.cal_nme(label, pred_label)
  nme.append(_nme)
print(np.mean(nme))

import argparse
import cv2
import sys
import numpy as np
import os
import mxnet as mx
import datetime
from pyquickhelper import imghelper
sys.path.append(os.path.join(os.path.dirname('insightface'), '..', 'deploy'))
from mtcnn import MTCNN


class Handler:
  def __init__(self, prefix, epoch, ctx_id=0):
    print('loading',prefix, epoch)
    if ctx_id>=0:
      ctx = mx.gpu(ctx_id)
    else:
      ctx = mx.cpu()
    sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)
    all_layers = sym.get_internals()
    sym = all_layers['heatmap_output']
    image_size = (128, 128)
    self.image_size = image_size
    model = mx.mod.Module(symbol=sym, context=ctx, label_names = None)
    #model = mx.mod.Module(symbol=sym, context=ctx)
    model.bind(for_training=False, data_shapes=[('data', (1, 3, image_size[0], image_size[1]))])
    model.set_params(arg_params, aux_params)
    self.model = model
    mtcnn_path = os.path.join(os.path.dirname(__file__), '..', 'deploy', 'mtcnn-model')
    self.det_threshold = [0.6,0.7,0.8]
    self.detector = MtcnnDetector(model_folder=mtcnn_path, ctx=ctx, num_worker=1, accurate_landmark = True, threshold=self.det_threshold)
  
  def get(self, img):
    ret = self.detector.detect_face(img, det_type = 0)
    if ret is None:
      return None
    bbox, points = ret
    if bbox.shape[0]==0:
      return None
    bbox = bbox[0,0:4]
    points = points[0,:].reshape((2,5)).T
    M = img_helper.estimate_trans_bbox(bbox, self.image_size[0], s = 2.0)
    rimg = cv2.warpAffine(img, M, self.image_size, borderValue = 0.0)
    img = cv2.cvtColor(rimg, cv2.COLOR_BGR2RGB)
    img = np.transpose(img, (2,0,1)) #3*112*112, RGB
    input_blob = np.zeros( (1, 3, self.image_size[1], self.image_size[0]),dtype=np.uint8 )
    input_blob[0] = img
    ta = datetime.datetime.now()
    data = mx.nd.array(input_blob)
    db = mx.io.DataBatch(data=(data,))
    self.model.forward(db, is_train=False)
    alabel = self.model.get_outputs()[-1].asnumpy()[0]
    tb = datetime.datetime.now()
    print('module time cost', (tb-ta).total_seconds())
    ret = np.zeros( (alabel.shape[0], 2), dtype=np.float32)
    for i in range(alabel.shape[0]):
      a = cv2.resize(alabel[i], (self.image_size[1], self.image_size[0]))
      ind = np.unravel_index(np.argmax(a, axis=None), a.shape)
      #ret[i] = (ind[0], ind[1]) #h, w
      ret[i] = (ind[1], ind[0]) #w, h
    return ret, M

ctx_id = 4
img_path = '../deploy/Tom_Hanks_54745.png'
img = cv2.imread(img_path)
#img = np.zeros( (128,128,3), dtype=np.uint8 )

handler = Handler('./model/HG', 1, ctx_id)
for _ in range(10):
  ta = datetime.datetime.now()
  landmark, M = handler.get(img)
  tb = datetime.datetime.now()
  print('get time cost', (tb-ta).total_seconds())
#visualize landmark
IM = cv2.invertAffineTransform(M)
for i in range(landmark.shape[0]):
  p = landmark[i]
  point = np.ones( (3,), dtype=np.float32)
  point[0:2] = p
  point = np.dot(IM, point)
  landmark[i] = point[0:2]

for i in range(landmark.shape[0]):
  p = landmark[i]
  point = (int(p[0]), int(p[1]))
  cv2.circle(img, point, 1, (0, 255, 0), 2)

filename = './landmark_test.png'
print('writing', filename)
cv2.imwrite(filename, img)

pip install mtcnn